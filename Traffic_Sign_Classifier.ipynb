{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages, which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission if necessary. \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission. \n",
    "\n",
    "In addition to implementing code, there is a writeup to complete. The writeup should be completed in a separate file, which can be either a markdown file or a pdf document. There is a [write up template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) that can be used to guide the writing process. Completing the code template and writeup template will cover all of the [rubric points](https://review.udacity.com/#!/rubrics/481/view) for this project.\n",
    "\n",
    "The [rubric](https://review.udacity.com/#!/rubrics/481/view) contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this Ipython notebook and also discuss the results in the writeup file.\n",
    "\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import tensorflow as tf\n",
    "from hashlib import md5\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from importlib import reload\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import helpers as h \n",
    "import architectures as arch\n",
    "\n",
    "if os.name == \"nt\" : # running on windows\n",
    "    DATA_DIR = \"C:/_DATA/autonomous-driving-nd/traffic_signs_classifier/\"\n",
    "    MY_DEV = \"/cpu:0\"\n",
    "else : \n",
    "    DATA_DIR = \"../data/\"\n",
    "    MY_DEV = \"/gpu:0\"\n",
    "# These files were downloaded from the data directory in the workshop enviornment\n",
    "training_file   = DATA_DIR + \"train.p\"\n",
    "validation_file = DATA_DIR + \"valid.p\"\n",
    "testing_file    = DATA_DIR + \"test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train0, y_train = train['features'], train['labels']\n",
    "X_valid0, y_valid = valid['features'], valid['labels']\n",
    "X_test0, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the [pandas shape method](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html) might be useful for calculating some of the summary results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43  min_class = 0  max_class = 42\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = X_train0.shape[0]\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = X_valid0.shape[0]\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = X_test0.shape[0]\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train0.shape[1:3]\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "uniq_classes = np.unique( np.hstack( [y_train, y_test, y_valid] ) ) \n",
    "n_classes = len( uniq_classes ) \n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes,  \" min_class =\", np.min(uniq_classes), \" max_class =\", np.max(uniq_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc. \n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections. It can be interesting to look at the distribution of classes in the training, validation and test set. Is the distribution the same? Are there more examples of some classes than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 7\n",
    "example_indices = np.zeros( (n_classes, n_examples), dtype=np.int32)\n",
    "\n",
    "for cls in uniq_classes : \n",
    "    all_ = np.where( y_train  == cls )[0]\n",
    "    example_indices[cls, :] = all_[ np.random.choice(len(all_), n_examples) ]\n",
    "\n",
    "\n",
    "def plot_examples_classes( example_indices, X_train, min_cls, max_cls ) :\n",
    "    n_examples = example_indices.shape[1]\n",
    "\n",
    "    fig, axs = plt.subplots( max_cls - min_cls, n_examples, figsize=(10,10) )\n",
    "    fig.suptitle( f'Classes {min_cls} to {max_cls -1}')\n",
    "    for cls in range(min_cls, max_cls): \n",
    "        for ex_i in range(n_examples) :\n",
    "            ax = axs[cls - min_cls, ex_i]\n",
    "            img_idx = example_indices[cls, ex_i]\n",
    "            ax.imshow( X_train[ img_idx,...] )\n",
    "            ax.tick_params( axis='x', which='both', bottom=False,  top=False,  labelbottom=False) \n",
    "            ax.tick_params( axis='y', which='both', left=False,    labelleft=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples_classes( example_indices, X_train, 0, 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples_classes( example_indices, X_train, 10, 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples_classes( example_indices, X_train, 20, 32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples_classes( example_indices, X_train, 32, 43 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_tr_df = pd.DataFrame( {'cls' : y_train, 'train_cnt' : 1}) \n",
    "y_vl_df = pd.DataFrame( {'cls' : y_valid, 'valid_cnt' : 1}) \n",
    "y_ts_df = pd.DataFrame( {'cls' : y_test, 'test_cnt' : 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots( 1,3, figsize=(16,5) ) \n",
    "tr_cnts, vl_cnts, ts_cnts  = [ df.groupby('cls').sum() \n",
    "                              for df in [y_tr_df, y_vl_df, y_ts_df] ]\n",
    "\n",
    "joined = tr_cnts.join( vl_cnts ).join( ts_cnts )\n",
    "\n",
    "for col in joined.columns : \n",
    "    joined[ col.replace('cnt', 'pct') ] = joined[col] / joined[col].sum() * 100.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8,10))\n",
    "ax.set_title('Pct of signs ')\n",
    "joined[['train_pct', 'valid_pct', 'test_pct']].plot( kind='barh', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, `(pixel - 128)/ 128` is a quick way to approximately normalize the data and can be used in this project. \n",
    "\n",
    "Other pre-processing steps are optional. You can try different techniques to see if it improves performance. \n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = X_valid0[1]  # 245\n",
    "\n",
    "def preproc( img ) :\n",
    "    X_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV  )\n",
    "    X_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS  )\n",
    "\n",
    "    h, s, v  = X_hsv[:,:,0], X_hsv[:,:,1], X_hsv[:,:,2]\n",
    "    h2, l, s2  = X_hls[:,:,0], X_hls[:,:,1], X_hls[:,:,2]\n",
    "\n",
    "    edges_h = cv2.Canny(h,100,200)\n",
    "    edges_s = cv2.Canny(s,100,180)\n",
    "    \n",
    "    return [ img, h,s,v, l, edges_s, edges_s.sum(axis=0), edges_s.sum(axis=1) ]\n",
    "\n",
    "imgs = [X_valid0[i] for i in np.random.choice( X_valid0.shape[0], 10 ) ]\n",
    "results = [ preproc(img) for img in imgs ]\n",
    "\n",
    "n_images = 10\n",
    "\n",
    "fig, axs = plt.subplots( n_images, 8, figsize=(16,16) )\n",
    "for i, layers in enumerate( results ) :\n",
    "    axs[i, 0].imshow( layers[0] )\n",
    "    axs[i, 1].imshow( layers[1], cmap = 'gray')\n",
    "    axs[i, 2].imshow( layers[2], cmap = 'gray')\n",
    "    axs[i, 3].imshow( layers[3], cmap = 'gray')\n",
    "    #axs[i,4].imshow( l, cmap = 'gray')\n",
    "    axs[i, 4].imshow( layers[4], cmap = 'gray')\n",
    "    #axs[i, 5].imshow( s - (v-l), cmap = 'gray')\n",
    "    #axs[i, 5].imshow( layers[5], cmap = 'gray')\n",
    "    axs[i, 5].imshow( layers[5], cmap = 'gray')\n",
    "    axs[i, 7].plot( layers[6] )\n",
    "    axs[i, 6].plot( layers[7] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( s.flatten() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34799, 32, 32, 3), (4410, 32, 32, 3), (12630, 32, 32, 3), dtype('float32'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "import helpers as h \n",
    "import architectures as arch\n",
    "\n",
    "reload(h)\n",
    "\n",
    "#X_train, X_valid, X_test = [ h.preproc_hs( X ).astype( np.float32 ) for X in [X_train0, X_valid0, X_test0] ]\n",
    "X_train, X_valid, X_test = [ h.normalize_mean_std( X ).astype( np.float32 ) for X in [X_train0, X_valid0, X_test0] ]\n",
    "X_train.shape, X_valid.shape, X_test.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_3_3_c = [ None, # index=0 won't be used\n",
    "    { 'type'  : 'conv2d', 'W_pars' : ( 3, 3, 64),  'strides' : ( 1, 1, 1, 1),\n",
    "      'name'  : 'conv1'},\n",
    "\n",
    "    {  'type'    : 'max_pool', 'ksize'   : (1, 2, 2, 1), 'strides' : (1, 2, 2, 1),\n",
    "       'padding' : 'SAME', 'name'    : 'max_p1'  },\n",
    "\n",
    "    { 'type'  : 'conv2d', 'W_pars' : ( 3, 3, 32),  'strides' : ( 1, 1, 1, 1),\n",
    "      'name'  : 'conv2'},\n",
    "\n",
    "    { 'type'    : 'max_pool', 'ksize'   : (1, 2, 2, 1), 'strides' : (1, 2, 2, 1),\n",
    "      'padding' : 'SAME', 'name'    : 'max_p2'  },\n",
    "\n",
    "    { 'type'  : 'conv2d', 'W_pars' : ( 5, 5, 16),  'strides' : ( 1, 1, 1, 1),\n",
    "      'name'  : 'conv3'},\n",
    "\n",
    "    # layer 4 : max_pool\n",
    "    {  'type'    : 'max_pool', 'ksize' : (1, 2, 2, 1), 'strides' : (1, 2, 2, 1),\n",
    "       'padding' : 'SAME',   'name'  : 'max_p3'  },\n",
    "     # layer 5 : flatten\n",
    "    {  'type'    : 'flatten', 'name'    : 'flat1'},\n",
    "    #layer 6 : fully_connected\n",
    "    {  'type'    : 'fully_connected', 'out_dim' : 120, 'nonlinear' : tf.nn.relu, 'name'    : 'fc1'},\n",
    "    #layer 7 : fully_connected\n",
    "    {  'type'    : 'fully_connected', 'out_dim' : 84,  'nonlinear' : tf.nn.relu, 'name' : 'fc2'},\n",
    "    #layer 8 : fully_connected  - no relu afterwards\n",
    "    {  'type'    : 'fully_connected', 'out_dim' : 43,  'nonlinear' : None,   'name' : 'fc3' }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train0, X_valid0, X_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "from sklearn.utils import shuffle\n",
    "reload( h )\n",
    "reload( arch )\n",
    "\n",
    "data = { \"X_train\" : X_train, \"y_train\" : y_train,\n",
    "         \"X_valid\" : X_valid, \"y_valid\" : y_valid,\n",
    "         \"X_test\" : X_test, \"y_test\" : y_test     }\n",
    "\n",
    "hyp_pars = {\n",
    "    \"netw_arch_name\" : \"arch_3_3\",\n",
    "    #netw_arch = arch.arch_3_3, bs 256, lr 1e-4\n",
    "    \"learning_rate\" : 0.0002,\n",
    "    \"keep_prob\" : 0.5,    \n",
    "    \"batch_size\" : 5000, #256     \n",
    "}\n",
    "\n",
    "if os.name != 'nt' :\n",
    "    log_pars = { \"print_loss_every\" : 300,\n",
    "                 \"run_valid_every\"  : 300 }\n",
    "else : \n",
    "    log_pars = { \"print_loss_every\" : 3,\n",
    "                 \"run_valid_every\"  : 10 }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('09373329', 'experiment_results/exp_09373329.pkl')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def md5_digest_from_pars( hyp_pars, digest_len = 8) : \n",
    "    hyp_pars_str = str( sorted( list( hyp_pars.items() ) ) ) \n",
    "    md5_dig = md5( hyp_pars_str.encode(\"utf8\") ).hexdigest()[:digest_len]\n",
    "    out_path = \"experiment_results/exp_\" + md5_dig + \".pkl\"\n",
    "    return md5_dig, out_path \n",
    "\n",
    "md5_dig, out_path = md5_digest_from_pars( hyp_pars )\n",
    "md5_dig, out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 1/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.9,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_3eb42e7b.pklalready there.\n",
      "\n",
      " Experiment 2/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_51f797a7.pklalready there.\n",
      "\n",
      " Experiment 3/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.7,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_eb00d42f.pklalready there.\n",
      "\n",
      " Experiment 4/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.9,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_ba8cc667.pklalready there.\n",
      "\n",
      " Experiment 5/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_a5ab239c.pklalready there.\n",
      "\n",
      " Experiment 6/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.7,\n",
      " 'learning_rate': 0.0005,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_2b5d0361.pklalready there.\n",
      "\n",
      " Experiment 7/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.9,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_ba549f28.pklalready there.\n",
      "\n",
      " Experiment 8/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_c60d0af2.pklalready there.\n",
      "\n",
      " Experiment 9/36 :\n",
      "\n",
      "{'batch_size': 256,\n",
      " 'keep_prob': 0.7,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "experiment_results/exp_f203d447.pklalready there.\n",
      "\n",
      " Experiment 10/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.9,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      " 1 conv1        conv2d           [30, 30, 16]     #params:     448\n",
      " 2 max_p1       max_pool         [15, 15, 16]     #params:       0\n",
      " 3 conv2        conv2d           [13, 13, 32]     #params:    4640\n",
      " 4 max_p2       max_pool         [7, 7, 32]       #params:       0\n",
      " 5 conv3        conv2d           [3, 3, 16]       #params:   12816\n",
      " 6 max_p3       max_pool         [2, 2, 16]       #params:       0\n",
      " 7 flat1        flatten          [64]             #params:       0\n",
      " 8 fc1          fully_connected  [120]            #params:    7800\n",
      " 9 dropout_1    dropout          [120]            #params:       0\n",
      "10 fc2          fully_connected  [84]             #params:   10164\n",
      "11 dropout_2    dropout          [84]             #params:       0\n",
      "no non-linearity\n",
      "12 logits       fully_connected  [43]             #params:    3655\n",
      "Total params:   39523\n",
      "Initializing batches_generator: batch_size= 512 n_batches= 67\n",
      "**Epoch  1, Avg. Loss: 3.9717  Train accuracy:  0.0051  Valid. accuracy: 0.0361 elapsed=3.33\n",
      "**Epoch  2, Avg. Loss: 3.7708  Train accuracy:  0.0048  Valid. accuracy: 0.0476 elapsed=1.88\n",
      "**Epoch  3, Avg. Loss: 3.7444  Train accuracy:  0.0130  Valid. accuracy: 0.0494 elapsed=1.87\n",
      "**Epoch  4, Avg. Loss: 3.7247  Train accuracy:  0.0041  Valid. accuracy: 0.0526 elapsed=1.89\n",
      "**Epoch  5, Avg. Loss: 3.7304  Train accuracy:  0.0148  Valid. accuracy: 0.0542 elapsed=1.89\n",
      "**Epoch  6, Avg. Loss: 3.6723  Train accuracy:  0.0106  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch  7, Avg. Loss: 3.6374  Train accuracy:  0.0163  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch  8, Avg. Loss: 3.5956  Train accuracy:  0.0088  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch  9, Avg. Loss: 3.5703  Train accuracy:  0.0138  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 10, Avg. Loss: 3.5518  Train accuracy:  0.0168  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 11, Avg. Loss: 3.5380  Train accuracy:  0.0141  Valid. accuracy: 0.0739 elapsed=1.88\n",
      "**Epoch 12, Avg. Loss: 3.5515  Train accuracy:  0.0189  Valid. accuracy: 0.0558 elapsed=1.87\n",
      "**Epoch 13, Avg. Loss: 3.5471  Train accuracy:  0.0574  Valid. accuracy: 0.0553 elapsed=1.88\n",
      "**Epoch 14, Avg. Loss: 3.5240  Train accuracy:  0.0379  Valid. accuracy: 0.0599 elapsed=1.89\n",
      "**Epoch 15, Avg. Loss: 3.4498  Train accuracy:  0.0221  Valid. accuracy: 0.0914 elapsed=1.88\n",
      "**Epoch 16, Avg. Loss: 3.3970  Train accuracy:  0.0573  Valid. accuracy: 0.0673 elapsed=1.89\n",
      "**Epoch 17, Avg. Loss: 3.2722  Train accuracy:  0.1264  Valid. accuracy: 0.1118 elapsed=1.89\n",
      "**Epoch 18, Avg. Loss: 3.1927  Train accuracy:  0.1038  Valid. accuracy: 0.1206 elapsed=1.88\n",
      "**Epoch 19, Avg. Loss: 3.0711  Train accuracy:  0.1472  Valid. accuracy: 0.1050 elapsed=1.89\n",
      "**Epoch 20, Avg. Loss: 2.9676  Train accuracy:  0.1377  Valid. accuracy: 0.1696 elapsed=1.88\n",
      "**Epoch 21, Avg. Loss: 3.1841  Train accuracy:  0.1001  Valid. accuracy: 0.1943 elapsed=1.90\n",
      "**Epoch 22, Avg. Loss: 3.0690  Train accuracy:  0.0891  Valid. accuracy: 0.1943 elapsed=1.89\n",
      "**Epoch 23, Avg. Loss: 2.8454  Train accuracy:  0.1310  Valid. accuracy: 0.2336 elapsed=1.90\n",
      "**Epoch 24, Avg. Loss: 2.6784  Train accuracy:  0.1664  Valid. accuracy: 0.2662 elapsed=1.90\n",
      "**Epoch 25, Avg. Loss: 2.5581  Train accuracy:  0.1967  Valid. accuracy: 0.2735 elapsed=1.88\n",
      "**Epoch 26, Avg. Loss: 2.4251  Train accuracy:  0.2396  Valid. accuracy: 0.2512 elapsed=1.88\n",
      "**Epoch 27, Avg. Loss: 2.3994  Train accuracy:  0.2082  Valid. accuracy: 0.3184 elapsed=1.89\n",
      "**Epoch 28, Avg. Loss: 2.2205  Train accuracy:  0.2554  Valid. accuracy: 0.3295 elapsed=1.89\n",
      "**Epoch 29, Avg. Loss: 2.1789  Train accuracy:  0.2553  Valid. accuracy: 0.3435 elapsed=1.90\n",
      "**Epoch 30, Avg. Loss: 2.0878  Train accuracy:  0.2858  Valid. accuracy: 0.3610 elapsed=1.90\n",
      "**Epoch 31, Avg. Loss: 1.9981  Train accuracy:  0.2935  Valid. accuracy: 0.3778 elapsed=1.87\n",
      "**Epoch 32, Avg. Loss: 1.9274  Train accuracy:  0.3145  Valid. accuracy: 0.4016 elapsed=1.89\n",
      "**Epoch 33, Avg. Loss: 1.8624  Train accuracy:  0.3567  Valid. accuracy: 0.4224 elapsed=1.89\n",
      "**Epoch 34, Avg. Loss: 1.7840  Train accuracy:  0.3694  Valid. accuracy: 0.4669 elapsed=1.89\n",
      "**Epoch 35, Avg. Loss: 1.6800  Train accuracy:  0.4023  Valid. accuracy: 0.4671 elapsed=1.88\n",
      "**Epoch 36, Avg. Loss: 1.6123  Train accuracy:  0.4167  Valid. accuracy: 0.4873 elapsed=1.89\n",
      "**Epoch 37, Avg. Loss: 1.5520  Train accuracy:  0.4337  Valid. accuracy: 0.4698 elapsed=1.88\n",
      "**Epoch 38, Avg. Loss: 1.5391  Train accuracy:  0.4448  Valid. accuracy: 0.4424 elapsed=1.88\n",
      "**Epoch 39, Avg. Loss: 1.5628  Train accuracy:  0.4363  Valid. accuracy: 0.4308 elapsed=1.88\n",
      "**Epoch 40, Avg. Loss: 1.5310  Train accuracy:  0.4696  Valid. accuracy: 0.5075 elapsed=1.89\n",
      "**Epoch 41, Avg. Loss: 1.5381  Train accuracy:  0.4552  Valid. accuracy: 0.5304 elapsed=1.90\n",
      "**Epoch 42, Avg. Loss: 1.4815  Train accuracy:  0.4816  Valid. accuracy: 0.5206 elapsed=1.88\n",
      "**Epoch 43, Avg. Loss: 1.4660  Train accuracy:  0.5096  Valid. accuracy: 0.5195 elapsed=1.87\n",
      "**Epoch 44, Avg. Loss: 1.5421  Train accuracy:  0.4761  Valid. accuracy: 0.5930 elapsed=1.89\n",
      "**Epoch 45, Avg. Loss: 1.2724  Train accuracy:  0.5400  Valid. accuracy: 0.6234 elapsed=1.88\n",
      "**Epoch 46, Avg. Loss: 1.1696  Train accuracy:  0.5614  Valid. accuracy: 0.6229 elapsed=1.90\n",
      "**Epoch 47, Avg. Loss: 1.1021  Train accuracy:  0.5855  Valid. accuracy: 0.6315 elapsed=1.91\n",
      "**Epoch 48, Avg. Loss: 1.0536  Train accuracy:  0.5998  Valid. accuracy: 0.6517 elapsed=1.88\n",
      "**Epoch 49, Avg. Loss: 1.0037  Train accuracy:  0.6230  Valid. accuracy: 0.6730 elapsed=1.88\n",
      "**Epoch 50, Avg. Loss: 0.9660  Train accuracy:  0.6351  Valid. accuracy: 0.6850 elapsed=1.87\n",
      "**Epoch 51, Avg. Loss: 0.9320  Train accuracy:  0.6496  Valid. accuracy: 0.6998 elapsed=1.87\n",
      "**Epoch 52, Avg. Loss: 0.8919  Train accuracy:  0.6725  Valid. accuracy: 0.7200 elapsed=1.87\n",
      "**Epoch 53, Avg. Loss: 0.8690  Train accuracy:  0.6821  Valid. accuracy: 0.6909 elapsed=1.87\n",
      "**Epoch 54, Avg. Loss: 0.8430  Train accuracy:  0.6967  Valid. accuracy: 0.6687 elapsed=1.88\n",
      "**Epoch 55, Avg. Loss: 0.9075  Train accuracy:  0.6668  Valid. accuracy: 0.7383 elapsed=1.86\n",
      "**Epoch 56, Avg. Loss: 0.7947  Train accuracy:  0.6912  Valid. accuracy: 0.7576 elapsed=1.87\n",
      "**Epoch 57, Avg. Loss: 0.6982  Train accuracy:  0.7214  Valid. accuracy: 0.7810 elapsed=1.86\n",
      "**Epoch 58, Avg. Loss: 0.6212  Train accuracy:  0.7509  Valid. accuracy: 0.7893 elapsed=1.85\n",
      "**Epoch 59, Avg. Loss: 0.5788  Train accuracy:  0.7756  Valid. accuracy: 0.7866 elapsed=1.86\n",
      "**Epoch 60, Avg. Loss: 0.5591  Train accuracy:  0.7857  Valid. accuracy: 0.7819 elapsed=1.87\n",
      "**Epoch 61, Avg. Loss: 0.5402  Train accuracy:  0.7918  Valid. accuracy: 0.8027 elapsed=1.88\n",
      "**Epoch 62, Avg. Loss: 0.5456  Train accuracy:  0.7898  Valid. accuracy: 0.8240 elapsed=1.88\n",
      "**Epoch 63, Avg. Loss: 0.4947  Train accuracy:  0.8192  Valid. accuracy: 0.7977 elapsed=1.88\n",
      "**Epoch 64, Avg. Loss: 0.4631  Train accuracy:  0.8226  Valid. accuracy: 0.8224 elapsed=1.88\n",
      "**Epoch 65, Avg. Loss: 0.4417  Train accuracy:  0.8299  Valid. accuracy: 0.8347 elapsed=1.87\n",
      "**Epoch 66, Avg. Loss: 0.4043  Train accuracy:  0.8453  Valid. accuracy: 0.8469 elapsed=1.88\n",
      "**Epoch 67, Avg. Loss: 0.3726  Train accuracy:  0.8594  Valid. accuracy: 0.8658 elapsed=1.89\n",
      "**Epoch 68, Avg. Loss: 0.3262  Train accuracy:  0.8788  Valid. accuracy: 0.8717 elapsed=1.88\n",
      "**Epoch 69, Avg. Loss: 0.3086  Train accuracy:  0.8879  Valid. accuracy: 0.8821 elapsed=1.88\n",
      "**Epoch 70, Avg. Loss: 0.2816  Train accuracy:  0.9016  Valid. accuracy: 0.8850 elapsed=1.88\n",
      "**Epoch 71, Avg. Loss: 0.2552  Train accuracy:  0.9116  Valid. accuracy: 0.8848 elapsed=1.89\n",
      "**Epoch 72, Avg. Loss: 0.2501  Train accuracy:  0.9111  Valid. accuracy: 0.8887 elapsed=1.90\n",
      "**Epoch 73, Avg. Loss: 0.2277  Train accuracy:  0.9200  Valid. accuracy: 0.8973 elapsed=1.88\n",
      "**Epoch 74, Avg. Loss: 0.1902  Train accuracy:  0.9369  Valid. accuracy: 0.9011 elapsed=1.87\n",
      "**Epoch 75, Avg. Loss: 0.1819  Train accuracy:  0.9400  Valid. accuracy: 0.9011 elapsed=1.89\n",
      "**Epoch 76, Avg. Loss: 0.1710  Train accuracy:  0.9435  Valid. accuracy: 0.9023 elapsed=1.90\n",
      "**Epoch 77, Avg. Loss: 0.1569  Train accuracy:  0.9485  Valid. accuracy: 0.9041 elapsed=1.90\n",
      "**Epoch 78, Avg. Loss: 0.1470  Train accuracy:  0.9524  Valid. accuracy: 0.8975 elapsed=1.87\n",
      "**Epoch 79, Avg. Loss: 0.1590  Train accuracy:  0.9483  Valid. accuracy: 0.8898 elapsed=1.87\n",
      "**Epoch 80, Avg. Loss: 0.1953  Train accuracy:  0.9345  Valid. accuracy: 0.8773 elapsed=1.88\n",
      "**Epoch 81, Avg. Loss: 0.3596  Train accuracy:  0.8834  Valid. accuracy: 0.8850 elapsed=1.90\n",
      "**Epoch 82, Avg. Loss: 0.1880  Train accuracy:  0.9407  Valid. accuracy: 0.9195 elapsed=1.88\n",
      "**Epoch 83, Avg. Loss: 0.1463  Train accuracy:  0.9529  Valid. accuracy: 0.9175 elapsed=1.88\n",
      "**Epoch 84, Avg. Loss: 0.1185  Train accuracy:  0.9626  Valid. accuracy: 0.9204 elapsed=1.90\n",
      "**Epoch 85, Avg. Loss: 0.1042  Train accuracy:  0.9662  Valid. accuracy: 0.9147 elapsed=1.87\n",
      "**Epoch 86, Avg. Loss: 0.1918  Train accuracy:  0.9440  Valid. accuracy: 0.8698 elapsed=1.87\n",
      "**Epoch 87, Avg. Loss: 0.2319  Train accuracy:  0.9281  Valid. accuracy: 0.9007 elapsed=1.86\n",
      "**Epoch 88, Avg. Loss: 0.1045  Train accuracy:  0.9673  Valid. accuracy: 0.9120 elapsed=1.88\n",
      "**Epoch 89, Avg. Loss: 0.0836  Train accuracy:  0.9751  Valid. accuracy: 0.9206 elapsed=1.86\n",
      "**Epoch 90, Avg. Loss: 0.0729  Train accuracy:  0.9780  Valid. accuracy: 0.9245 elapsed=1.88\n",
      "**Epoch 91, Avg. Loss: 0.0587  Train accuracy:  0.9829  Valid. accuracy: 0.9277 elapsed=1.88\n",
      "**Epoch 92, Avg. Loss: 0.0485  Train accuracy:  0.9860  Valid. accuracy: 0.9317 elapsed=1.88\n",
      "**Epoch 93, Avg. Loss: 0.0438  Train accuracy:  0.9871  Valid. accuracy: 0.9317 elapsed=1.88\n",
      "**Epoch 94, Avg. Loss: 0.0389  Train accuracy:  0.9884  Valid. accuracy: 0.9308 elapsed=1.89\n",
      "**Epoch 95, Avg. Loss: 0.0332  Train accuracy:  0.9901  Valid. accuracy: 0.9347 elapsed=1.88\n",
      "**Epoch 96, Avg. Loss: 0.0331  Train accuracy:  0.9902  Valid. accuracy: 0.9354 elapsed=1.87\n",
      "**Epoch 97, Avg. Loss: 0.0268  Train accuracy:  0.9926  Valid. accuracy: 0.9354 elapsed=1.89\n",
      "**Epoch 98, Avg. Loss: 0.0254  Train accuracy:  0.9927  Valid. accuracy: 0.9338 elapsed=1.90\n",
      "**Epoch 99, Avg. Loss: 0.0253  Train accuracy:  0.9926  Valid. accuracy: 0.9358 elapsed=1.87\n",
      "**Epoch 100, Avg. Loss: 0.0240  Train accuracy:  0.9925  Valid. accuracy: 0.9345 elapsed=1.88\n",
      "**Epoch 101, Avg. Loss: 0.0231  Train accuracy:  0.9931  Valid. accuracy: 0.9351 elapsed=1.91\n",
      "**Epoch 102, Avg. Loss: 0.0208  Train accuracy:  0.9934  Valid. accuracy: 0.9372 elapsed=1.90\n",
      "**Epoch 103, Avg. Loss: 0.0179  Train accuracy:  0.9951  Valid. accuracy: 0.9385 elapsed=1.91\n",
      "**Epoch 104, Avg. Loss: 0.0156  Train accuracy:  0.9958  Valid. accuracy: 0.9329 elapsed=1.88\n",
      "**Epoch 105, Avg. Loss: 0.0153  Train accuracy:  0.9956  Valid. accuracy: 0.9381 elapsed=1.88\n",
      "**Epoch 106, Avg. Loss: 0.0144  Train accuracy:  0.9959  Valid. accuracy: 0.9381 elapsed=1.87\n",
      "**Epoch 107, Avg. Loss: 0.0144  Train accuracy:  0.9960  Valid. accuracy: 0.9372 elapsed=1.88\n",
      "**Epoch 108, Avg. Loss: 0.0169  Train accuracy:  0.9951  Valid. accuracy: 0.9379 elapsed=1.88\n",
      "**Epoch 109, Avg. Loss: 0.0162  Train accuracy:  0.9948  Valid. accuracy: 0.9404 elapsed=1.90\n",
      "**Epoch 110, Avg. Loss: 0.0164  Train accuracy:  0.9947  Valid. accuracy: 0.9349 elapsed=1.87\n",
      "**Epoch 111, Avg. Loss: 0.0133  Train accuracy:  0.9963  Valid. accuracy: 0.9383 elapsed=1.87\n",
      "**Epoch 112, Avg. Loss: 0.0115  Train accuracy:  0.9969  Valid. accuracy: 0.9340 elapsed=1.87\n",
      "**Epoch 113, Avg. Loss: 0.0098  Train accuracy:  0.9973  Valid. accuracy: 0.9410 elapsed=1.90\n",
      "**Epoch 114, Avg. Loss: 0.0104  Train accuracy:  0.9975  Valid. accuracy: 0.9363 elapsed=1.91\n",
      "**Epoch 115, Avg. Loss: 0.0092  Train accuracy:  0.9976  Valid. accuracy: 0.9397 elapsed=1.91\n",
      "**Epoch 116, Avg. Loss: 0.0096  Train accuracy:  0.9971  Valid. accuracy: 0.9367 elapsed=1.90\n",
      "**Epoch 117, Avg. Loss: 0.0096  Train accuracy:  0.9972  Valid. accuracy: 0.9367 elapsed=1.90\n",
      "**Epoch 118, Avg. Loss: 0.0097  Train accuracy:  0.9973  Valid. accuracy: 0.9408 elapsed=1.89\n",
      "**Epoch 119, Avg. Loss: 0.0101  Train accuracy:  0.9972  Valid. accuracy: 0.9415 elapsed=1.88\n",
      "**Epoch 120, Avg. Loss: 0.0087  Train accuracy:  0.9974  Valid. accuracy: 0.9415 elapsed=1.91\n",
      "**Epoch 121, Avg. Loss: 0.0092  Train accuracy:  0.9973  Valid. accuracy: 0.9426 elapsed=1.90\n",
      "**Epoch 122, Avg. Loss: 0.0078  Train accuracy:  0.9982  Valid. accuracy: 0.9376 elapsed=1.90\n",
      "**Epoch 123, Avg. Loss: 0.0058  Train accuracy:  0.9986  Valid. accuracy: 0.9417 elapsed=1.90\n",
      "**Epoch 124, Avg. Loss: 0.0075  Train accuracy:  0.9982  Valid. accuracy: 0.9374 elapsed=1.88\n",
      "**Epoch 125, Avg. Loss: 0.0076  Train accuracy:  0.9980  Valid. accuracy: 0.9376 elapsed=1.89\n",
      "**Epoch 126, Avg. Loss: 0.0086  Train accuracy:  0.9975  Valid. accuracy: 0.9395 elapsed=1.87\n",
      "**Epoch 127, Avg. Loss: 0.0085  Train accuracy:  0.9977  Valid. accuracy: 0.9365 elapsed=1.93\n",
      "**Epoch 128, Avg. Loss: 0.0087  Train accuracy:  0.9975  Valid. accuracy: 0.9397 elapsed=1.91\n",
      "**Epoch 129, Avg. Loss: 0.0217  Train accuracy:  0.9925  Valid. accuracy: 0.9293 elapsed=1.91\n",
      "**Epoch 130, Avg. Loss: 0.2321  Train accuracy:  0.9448  Valid. accuracy: 0.8297 elapsed=1.89\n",
      "**Epoch 131, Avg. Loss: 1.0668  Train accuracy:  0.7506  Valid. accuracy: 0.6753 elapsed=1.89\n",
      "**Epoch 132, Avg. Loss: 0.9939  Train accuracy:  0.7150  Valid. accuracy: 0.8361 elapsed=1.90\n",
      "**Epoch 133, Avg. Loss: 0.4655  Train accuracy:  0.8504  Valid. accuracy: 0.8968 elapsed=1.90\n",
      "**Epoch 134, Avg. Loss: 0.1852  Train accuracy:  0.9433  Valid. accuracy: 0.9249 elapsed=1.91\n",
      "**Epoch 135, Avg. Loss: 0.0819  Train accuracy:  0.9774  Valid. accuracy: 0.9295 elapsed=1.87\n",
      "**Epoch 136, Avg. Loss: 0.0527  Train accuracy:  0.9853  Valid. accuracy: 0.9297 elapsed=1.88\n",
      "**Epoch 137, Avg. Loss: 0.0396  Train accuracy:  0.9901  Valid. accuracy: 0.9320 elapsed=1.88\n",
      "**Epoch 138, Avg. Loss: 0.0302  Train accuracy:  0.9922  Valid. accuracy: 0.9329 elapsed=1.91\n",
      "**Epoch 139, Avg. Loss: 0.0257  Train accuracy:  0.9932  Valid. accuracy: 0.9336 elapsed=1.89\n",
      "**Epoch 140, Avg. Loss: 0.0211  Train accuracy:  0.9946  Valid. accuracy: 0.9361 elapsed=1.89\n",
      "**Epoch 141, Avg. Loss: 0.0180  Train accuracy:  0.9958  Valid. accuracy: 0.9358 elapsed=1.87\n",
      "**Epoch 142, Avg. Loss: 0.0158  Train accuracy:  0.9964  Valid. accuracy: 0.9376 elapsed=1.90\n",
      "**Epoch 143, Avg. Loss: 0.0133  Train accuracy:  0.9969  Valid. accuracy: 0.9354 elapsed=1.90\n",
      "**Epoch 144, Avg. Loss: 0.0118  Train accuracy:  0.9972  Valid. accuracy: 0.9347 elapsed=1.91\n",
      "**Epoch 145, Avg. Loss: 0.0108  Train accuracy:  0.9974  Valid. accuracy: 0.9381 elapsed=1.89\n",
      "**Epoch 146, Avg. Loss: 0.0104  Train accuracy:  0.9974  Valid. accuracy: 0.9376 elapsed=1.89\n",
      "**Epoch 147, Avg. Loss: 0.0085  Train accuracy:  0.9983  Valid. accuracy: 0.9381 elapsed=1.88\n",
      "**Epoch 148, Avg. Loss: 0.0081  Train accuracy:  0.9981  Valid. accuracy: 0.9392 elapsed=1.90\n",
      "**Epoch 149, Avg. Loss: 0.0075  Train accuracy:  0.9983  Valid. accuracy: 0.9399 elapsed=1.90\n",
      "**Epoch 150, Avg. Loss: 0.0065  Train accuracy:  0.9986  Valid. accuracy: 0.9376 elapsed=1.91\n",
      "**Epoch 151, Avg. Loss: 0.0057  Train accuracy:  0.9985  Valid. accuracy: 0.9372 elapsed=1.92\n",
      "**Epoch 152, Avg. Loss: 0.0061  Train accuracy:  0.9988  Valid. accuracy: 0.9392 elapsed=1.91\n",
      "**Epoch 153, Avg. Loss: 0.0054  Train accuracy:  0.9988  Valid. accuracy: 0.9365 elapsed=1.90\n",
      "**Epoch 154, Avg. Loss: 0.0046  Train accuracy:  0.9990  Valid. accuracy: 0.9397 elapsed=1.89\n",
      "**Epoch 155, Avg. Loss: 0.0047  Train accuracy:  0.9989  Valid. accuracy: 0.9399 elapsed=1.90\n",
      "**Epoch 156, Avg. Loss: 0.0049  Train accuracy:  0.9987  Valid. accuracy: 0.9388 elapsed=1.92\n",
      "**Epoch 157, Avg. Loss: 0.0044  Train accuracy:  0.9990  Valid. accuracy: 0.9383 elapsed=1.91\n",
      "**Epoch 158, Avg. Loss: 0.0046  Train accuracy:  0.9990  Valid. accuracy: 0.9392 elapsed=1.90\n",
      "**Epoch 159, Avg. Loss: 0.0042  Train accuracy:  0.9990  Valid. accuracy: 0.9388 elapsed=1.88\n",
      "**Epoch 160, Avg. Loss: 0.0043  Train accuracy:  0.9991  Valid. accuracy: 0.9401 elapsed=1.88\n",
      "**Epoch 161, Avg. Loss: 0.0044  Train accuracy:  0.9989  Valid. accuracy: 0.9395 elapsed=1.89\n",
      "**Epoch 162, Avg. Loss: 0.0034  Train accuracy:  0.9994  Valid. accuracy: 0.9390 elapsed=1.91\n",
      "**Epoch 163, Avg. Loss: 0.0040  Train accuracy:  0.9990  Valid. accuracy: 0.9385 elapsed=1.91\n",
      "**Epoch 164, Avg. Loss: 0.0038  Train accuracy:  0.9991  Valid. accuracy: 0.9406 elapsed=1.90\n",
      "**Epoch 165, Avg. Loss: 0.0036  Train accuracy:  0.9991  Valid. accuracy: 0.9401 elapsed=1.91\n",
      "**Epoch 166, Avg. Loss: 0.0030  Train accuracy:  0.9994  Valid. accuracy: 0.9429 elapsed=1.91\n",
      "**Epoch 167, Avg. Loss: 0.0028  Train accuracy:  0.9994  Valid. accuracy: 0.9429 elapsed=1.90\n",
      "**Epoch 168, Avg. Loss: 0.0025  Train accuracy:  0.9994  Valid. accuracy: 0.9420 elapsed=1.88\n",
      "**Epoch 169, Avg. Loss: 0.0032  Train accuracy:  0.9990  Valid. accuracy: 0.9431 elapsed=1.88\n",
      "**Epoch 170, Avg. Loss: 0.0023  Train accuracy:  0.9994  Valid. accuracy: 0.9417 elapsed=1.86\n",
      "**Epoch 171, Avg. Loss: 0.0031  Train accuracy:  0.9992  Valid. accuracy: 0.9413 elapsed=1.90\n",
      "**Epoch 172, Avg. Loss: 0.0027  Train accuracy:  0.9993  Valid. accuracy: 0.9420 elapsed=1.91\n",
      "**Epoch 173, Avg. Loss: 0.0024  Train accuracy:  0.9993  Valid. accuracy: 0.9451 elapsed=1.87\n",
      "**Epoch 174, Avg. Loss: 0.0034  Train accuracy:  0.9991  Valid. accuracy: 0.9374 elapsed=1.89\n",
      "**Epoch 175, Avg. Loss: 0.0056  Train accuracy:  0.9986  Valid. accuracy: 0.9236 elapsed=1.88\n",
      "**Epoch 176, Avg. Loss: 0.8230  Train accuracy:  0.8470  Valid. accuracy: 0.7168 elapsed=1.88\n",
      "**Epoch 177, Avg. Loss: 0.7677  Train accuracy:  0.7914  Valid. accuracy: 0.8664 elapsed=1.90\n",
      "**Epoch 178, Avg. Loss: 0.2510  Train accuracy:  0.9230  Valid. accuracy: 0.9265 elapsed=1.90\n",
      "**Epoch 179, Avg. Loss: 0.1415  Train accuracy:  0.9562  Valid. accuracy: 0.9231 elapsed=1.88\n",
      "**Epoch 180, Avg. Loss: 0.0691  Train accuracy:  0.9787  Valid. accuracy: 0.9349 elapsed=1.89\n",
      "**Epoch 181, Avg. Loss: 0.0284  Train accuracy:  0.9928  Valid. accuracy: 0.9381 elapsed=1.88\n",
      "**Epoch 182, Avg. Loss: 0.0188  Train accuracy:  0.9952  Valid. accuracy: 0.9379 elapsed=1.90\n",
      "**Epoch 183, Avg. Loss: 0.0163  Train accuracy:  0.9955  Valid. accuracy: 0.9392 elapsed=1.88\n",
      "**Epoch 184, Avg. Loss: 0.0131  Train accuracy:  0.9969  Valid. accuracy: 0.9390 elapsed=1.88\n",
      "**Epoch 185, Avg. Loss: 0.0109  Train accuracy:  0.9976  Valid. accuracy: 0.9401 elapsed=1.88\n",
      "**Epoch 186, Avg. Loss: 0.0087  Train accuracy:  0.9983  Valid. accuracy: 0.9379 elapsed=1.89\n",
      "**Epoch 187, Avg. Loss: 0.0076  Train accuracy:  0.9984  Valid. accuracy: 0.9397 elapsed=1.91\n",
      "**Epoch 188, Avg. Loss: 0.0066  Train accuracy:  0.9987  Valid. accuracy: 0.9395 elapsed=1.89\n",
      "**Epoch 189, Avg. Loss: 0.0061  Train accuracy:  0.9989  Valid. accuracy: 0.9408 elapsed=1.87\n",
      "**Epoch 190, Avg. Loss: 0.0063  Train accuracy:  0.9985  Valid. accuracy: 0.9417 elapsed=1.89\n",
      "**Epoch 191, Avg. Loss: 0.0051  Train accuracy:  0.9988  Valid. accuracy: 0.9420 elapsed=1.88\n",
      "**Epoch 192, Avg. Loss: 0.0047  Train accuracy:  0.9992  Valid. accuracy: 0.9438 elapsed=1.87\n",
      "**Epoch 193, Avg. Loss: 0.0041  Train accuracy:  0.9992  Valid. accuracy: 0.9420 elapsed=1.88\n",
      "**Epoch 194, Avg. Loss: 0.0051  Train accuracy:  0.9987  Valid. accuracy: 0.9424 elapsed=1.89\n",
      "**Epoch 195, Avg. Loss: 0.0035  Train accuracy:  0.9992  Valid. accuracy: 0.9422 elapsed=1.89\n",
      "**Epoch 196, Avg. Loss: 0.0040  Train accuracy:  0.9990  Valid. accuracy: 0.9433 elapsed=1.89\n",
      "**Epoch 197, Avg. Loss: 0.0036  Train accuracy:  0.9993  Valid. accuracy: 0.9465 elapsed=1.87\n",
      "**Epoch 198, Avg. Loss: 0.0043  Train accuracy:  0.9991  Valid. accuracy: 0.9451 elapsed=1.87\n",
      "**Epoch 199, Avg. Loss: 0.0033  Train accuracy:  0.9992  Valid. accuracy: 0.9451 elapsed=1.87\n",
      "**Epoch 200, Avg. Loss: 0.0032  Train accuracy:  0.9994  Valid. accuracy: 0.9456 elapsed=1.88\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.9,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "Writing to experiment_results/exp_bbdeea99.pkl\n",
      "\n",
      " Experiment 11/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      " 1 conv1        conv2d           [30, 30, 16]     #params:     448\n",
      " 2 max_p1       max_pool         [15, 15, 16]     #params:       0\n",
      " 3 conv2        conv2d           [13, 13, 32]     #params:    4640\n",
      " 4 max_p2       max_pool         [7, 7, 32]       #params:       0\n",
      " 5 conv3        conv2d           [3, 3, 16]       #params:   12816\n",
      " 6 max_p3       max_pool         [2, 2, 16]       #params:       0\n",
      " 7 flat1        flatten          [64]             #params:       0\n",
      " 8 fc1          fully_connected  [120]            #params:    7800\n",
      " 9 dropout_1    dropout          [120]            #params:       0\n",
      "10 fc2          fully_connected  [84]             #params:   10164\n",
      "11 dropout_2    dropout          [84]             #params:       0\n",
      "no non-linearity\n",
      "12 logits       fully_connected  [43]             #params:    3655\n",
      "Total params:   39523\n",
      "Initializing batches_generator: batch_size= 512 n_batches= 67\n",
      "**Epoch  1, Avg. Loss: 3.7914  Train accuracy:  0.0167  Valid. accuracy: 0.0200 elapsed=1.91\n",
      "**Epoch  2, Avg. Loss: 3.7578  Train accuracy:  0.0102  Valid. accuracy: 0.0340 elapsed=1.88\n",
      "**Epoch  3, Avg. Loss: 3.7433  Train accuracy:  0.0110  Valid. accuracy: 0.0340 elapsed=1.88\n",
      "**Epoch  4, Avg. Loss: 3.7259  Train accuracy:  0.0249  Valid. accuracy: 0.0340 elapsed=1.88\n",
      "**Epoch  5, Avg. Loss: 3.7044  Train accuracy:  0.0298  Valid. accuracy: 0.0340 elapsed=1.90\n",
      "**Epoch  6, Avg. Loss: 3.6737  Train accuracy:  0.0329  Valid. accuracy: 0.0340 elapsed=1.91\n",
      "**Epoch  7, Avg. Loss: 3.6423  Train accuracy:  0.0338  Valid. accuracy: 0.0342 elapsed=1.91\n",
      "**Epoch  8, Avg. Loss: 3.6070  Train accuracy:  0.0351  Valid. accuracy: 0.0474 elapsed=1.92\n",
      "**Epoch  9, Avg. Loss: 3.5829  Train accuracy:  0.0393  Valid. accuracy: 0.0474 elapsed=1.90\n",
      "**Epoch 10, Avg. Loss: 3.5684  Train accuracy:  0.0386  Valid. accuracy: 0.0472 elapsed=1.89\n",
      "**Epoch 11, Avg. Loss: 3.5855  Train accuracy:  0.0383  Valid. accuracy: 0.0476 elapsed=1.89\n",
      "**Epoch 12, Avg. Loss: 3.5501  Train accuracy:  0.0299  Valid. accuracy: 0.0467 elapsed=1.88\n",
      "**Epoch 13, Avg. Loss: 3.5454  Train accuracy:  0.0287  Valid. accuracy: 0.0472 elapsed=1.89\n",
      "**Epoch 14, Avg. Loss: 3.5404  Train accuracy:  0.0260  Valid. accuracy: 0.0474 elapsed=1.89\n",
      "**Epoch 15, Avg. Loss: 3.5334  Train accuracy:  0.0251  Valid. accuracy: 0.0426 elapsed=1.90\n",
      "**Epoch 16, Avg. Loss: 3.5366  Train accuracy:  0.0214  Valid. accuracy: 0.0501 elapsed=1.91\n",
      "**Epoch 17, Avg. Loss: 3.5221  Train accuracy:  0.0231  Valid. accuracy: 0.0465 elapsed=1.90\n",
      "**Epoch 18, Avg. Loss: 3.5278  Train accuracy:  0.0324  Valid. accuracy: 0.0685 elapsed=1.89\n",
      "**Epoch 19, Avg. Loss: 3.6007  Train accuracy:  0.0719  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 20, Avg. Loss: 3.4678  Train accuracy:  0.0324  Valid. accuracy: 0.0565 elapsed=1.88\n",
      "**Epoch 21, Avg. Loss: 3.4410  Train accuracy:  0.0497  Valid. accuracy: 0.0630 elapsed=1.88\n",
      "**Epoch 22, Avg. Loss: 3.3909  Train accuracy:  0.0532  Valid. accuracy: 0.0540 elapsed=1.87\n",
      "**Epoch 23, Avg. Loss: 3.5007  Train accuracy:  0.0508  Valid. accuracy: 0.0719 elapsed=1.88\n",
      "**Epoch 24, Avg. Loss: 3.3397  Train accuracy:  0.0854  Valid. accuracy: 0.0619 elapsed=1.91\n",
      "**Epoch 25, Avg. Loss: 3.3034  Train accuracy:  0.0769  Valid. accuracy: 0.0789 elapsed=1.93\n",
      "**Epoch 26, Avg. Loss: 3.1717  Train accuracy:  0.0870  Valid. accuracy: 0.0998 elapsed=1.91\n",
      "**Epoch 27, Avg. Loss: 3.1172  Train accuracy:  0.0899  Valid. accuracy: 0.1259 elapsed=1.90\n",
      "**Epoch 28, Avg. Loss: 3.0525  Train accuracy:  0.0965  Valid. accuracy: 0.1458 elapsed=1.87\n",
      "**Epoch 29, Avg. Loss: 3.0108  Train accuracy:  0.1012  Valid. accuracy: 0.1744 elapsed=1.87\n",
      "**Epoch 30, Avg. Loss: 2.9527  Train accuracy:  0.1055  Valid. accuracy: 0.1909 elapsed=1.88\n",
      "**Epoch 31, Avg. Loss: 2.8903  Train accuracy:  0.1175  Valid. accuracy: 0.1658 elapsed=1.87\n",
      "**Epoch 32, Avg. Loss: 2.8036  Train accuracy:  0.1363  Valid. accuracy: 0.2052 elapsed=1.87\n",
      "**Epoch 33, Avg. Loss: 2.7768  Train accuracy:  0.1559  Valid. accuracy: 0.1948 elapsed=1.88\n",
      "**Epoch 34, Avg. Loss: 2.7081  Train accuracy:  0.1788  Valid. accuracy: 0.2302 elapsed=1.88\n",
      "**Epoch 35, Avg. Loss: 2.6493  Train accuracy:  0.1902  Valid. accuracy: 0.2406 elapsed=1.89\n",
      "**Epoch 36, Avg. Loss: 2.6284  Train accuracy:  0.1797  Valid. accuracy: 0.2483 elapsed=1.88\n",
      "**Epoch 37, Avg. Loss: 2.6897  Train accuracy:  0.1651  Valid. accuracy: 0.2426 elapsed=1.88\n",
      "**Epoch 38, Avg. Loss: 2.5978  Train accuracy:  0.1894  Valid. accuracy: 0.2442 elapsed=1.91\n",
      "**Epoch 39, Avg. Loss: 2.5519  Train accuracy:  0.2001  Valid. accuracy: 0.2338 elapsed=1.88\n",
      "**Epoch 40, Avg. Loss: 2.5111  Train accuracy:  0.2076  Valid. accuracy: 0.2229 elapsed=1.88\n",
      "**Epoch 41, Avg. Loss: 2.4783  Train accuracy:  0.2260  Valid. accuracy: 0.2184 elapsed=1.88\n",
      "**Epoch 42, Avg. Loss: 2.4325  Train accuracy:  0.2176  Valid. accuracy: 0.2512 elapsed=1.89\n",
      "**Epoch 43, Avg. Loss: 2.3392  Train accuracy:  0.2414  Valid. accuracy: 0.3224 elapsed=1.91\n",
      "**Epoch 44, Avg. Loss: 2.2461  Train accuracy:  0.2651  Valid. accuracy: 0.3469 elapsed=1.87\n",
      "**Epoch 45, Avg. Loss: 2.1325  Train accuracy:  0.3012  Valid. accuracy: 0.3662 elapsed=1.86\n",
      "**Epoch 46, Avg. Loss: 2.0324  Train accuracy:  0.3314  Valid. accuracy: 0.3751 elapsed=1.86\n",
      "**Epoch 47, Avg. Loss: 1.9473  Train accuracy:  0.3540  Valid. accuracy: 0.3932 elapsed=1.87\n",
      "**Epoch 48, Avg. Loss: 1.8677  Train accuracy:  0.3732  Valid. accuracy: 0.4066 elapsed=1.87\n",
      "**Epoch 49, Avg. Loss: 1.8105  Train accuracy:  0.3748  Valid. accuracy: 0.4109 elapsed=1.86\n",
      "**Epoch 50, Avg. Loss: 1.7279  Train accuracy:  0.4037  Valid. accuracy: 0.4508 elapsed=1.88\n",
      "**Epoch 51, Avg. Loss: 1.6517  Train accuracy:  0.4257  Valid. accuracy: 0.4503 elapsed=1.88\n",
      "**Epoch 52, Avg. Loss: 1.6411  Train accuracy:  0.4309  Valid. accuracy: 0.4488 elapsed=1.90\n",
      "**Epoch 53, Avg. Loss: 1.6060  Train accuracy:  0.4328  Valid. accuracy: 0.5011 elapsed=1.92\n",
      "**Epoch 54, Avg. Loss: 1.5863  Train accuracy:  0.4466  Valid. accuracy: 0.4846 elapsed=1.90\n",
      "**Epoch 55, Avg. Loss: 1.5306  Train accuracy:  0.4750  Valid. accuracy: 0.5125 elapsed=1.89\n",
      "**Epoch 56, Avg. Loss: 1.4729  Train accuracy:  0.4882  Valid. accuracy: 0.5583 elapsed=1.89\n",
      "**Epoch 57, Avg. Loss: 1.3805  Train accuracy:  0.5010  Valid. accuracy: 0.5914 elapsed=1.90\n",
      "**Epoch 58, Avg. Loss: 1.2906  Train accuracy:  0.5286  Valid. accuracy: 0.5934 elapsed=1.89\n",
      "**Epoch 59, Avg. Loss: 1.2213  Train accuracy:  0.5622  Valid. accuracy: 0.5912 elapsed=1.87\n",
      "**Epoch 60, Avg. Loss: 1.1853  Train accuracy:  0.5703  Valid. accuracy: 0.5973 elapsed=1.87\n",
      "**Epoch 61, Avg. Loss: 1.1556  Train accuracy:  0.5822  Valid. accuracy: 0.5995 elapsed=1.88\n",
      "**Epoch 62, Avg. Loss: 1.1112  Train accuracy:  0.6000  Valid. accuracy: 0.6476 elapsed=1.89\n",
      "**Epoch 63, Avg. Loss: 1.0464  Train accuracy:  0.6156  Valid. accuracy: 0.7000 elapsed=1.88\n",
      "**Epoch 64, Avg. Loss: 0.9660  Train accuracy:  0.6480  Valid. accuracy: 0.7166 elapsed=1.90\n",
      "**Epoch 65, Avg. Loss: 0.8993  Train accuracy:  0.6704  Valid. accuracy: 0.7227 elapsed=1.89\n",
      "**Epoch 66, Avg. Loss: 0.8283  Train accuracy:  0.6923  Valid. accuracy: 0.7324 elapsed=1.89\n",
      "**Epoch 67, Avg. Loss: 0.7962  Train accuracy:  0.7047  Valid. accuracy: 0.7354 elapsed=1.89\n",
      "**Epoch 68, Avg. Loss: 0.7708  Train accuracy:  0.7138  Valid. accuracy: 0.7320 elapsed=1.88\n",
      "**Epoch 69, Avg. Loss: 0.7311  Train accuracy:  0.7271  Valid. accuracy: 0.7259 elapsed=1.88\n",
      "**Epoch 70, Avg. Loss: 0.7060  Train accuracy:  0.7426  Valid. accuracy: 0.7585 elapsed=1.89\n",
      "**Epoch 71, Avg. Loss: 0.6962  Train accuracy:  0.7424  Valid. accuracy: 0.7841 elapsed=1.87\n",
      "**Epoch 72, Avg. Loss: 0.6859  Train accuracy:  0.7594  Valid. accuracy: 0.8150 elapsed=1.88\n",
      "**Epoch 73, Avg. Loss: 0.6537  Train accuracy:  0.7683  Valid. accuracy: 0.7898 elapsed=1.90\n",
      "**Epoch 74, Avg. Loss: 0.6681  Train accuracy:  0.7650  Valid. accuracy: 0.7934 elapsed=1.91\n",
      "**Epoch 75, Avg. Loss: 0.6091  Train accuracy:  0.7782  Valid. accuracy: 0.7927 elapsed=1.88\n",
      "**Epoch 76, Avg. Loss: 0.5530  Train accuracy:  0.7948  Valid. accuracy: 0.8172 elapsed=1.87\n",
      "**Epoch 77, Avg. Loss: 0.4954  Train accuracy:  0.8163  Valid. accuracy: 0.8426 elapsed=1.86\n",
      "**Epoch 78, Avg. Loss: 0.4533  Train accuracy:  0.8344  Valid. accuracy: 0.8490 elapsed=1.86\n",
      "**Epoch 79, Avg. Loss: 0.4161  Train accuracy:  0.8514  Valid. accuracy: 0.8583 elapsed=1.86\n",
      "**Epoch 80, Avg. Loss: 0.3768  Train accuracy:  0.8668  Valid. accuracy: 0.8689 elapsed=1.86\n",
      "**Epoch 81, Avg. Loss: 0.3499  Train accuracy:  0.8761  Valid. accuracy: 0.8732 elapsed=1.87\n",
      "**Epoch 82, Avg. Loss: 0.3297  Train accuracy:  0.8848  Valid. accuracy: 0.8839 elapsed=1.89\n",
      "**Epoch 83, Avg. Loss: 0.3101  Train accuracy:  0.8919  Valid. accuracy: 0.8794 elapsed=1.89\n",
      "**Epoch 84, Avg. Loss: 0.2871  Train accuracy:  0.9002  Valid. accuracy: 0.8864 elapsed=1.88\n",
      "**Epoch 85, Avg. Loss: 0.2721  Train accuracy:  0.9060  Valid. accuracy: 0.8848 elapsed=1.88\n",
      "**Epoch 86, Avg. Loss: 0.2671  Train accuracy:  0.9082  Valid. accuracy: 0.8862 elapsed=1.87\n",
      "**Epoch 87, Avg. Loss: 0.2666  Train accuracy:  0.9070  Valid. accuracy: 0.8907 elapsed=1.89\n",
      "**Epoch 88, Avg. Loss: 0.2411  Train accuracy:  0.9158  Valid. accuracy: 0.8934 elapsed=1.90\n",
      "**Epoch 89, Avg. Loss: 0.2232  Train accuracy:  0.9226  Valid. accuracy: 0.9009 elapsed=1.89\n",
      "**Epoch 90, Avg. Loss: 0.2127  Train accuracy:  0.9263  Valid. accuracy: 0.9020 elapsed=1.87\n",
      "**Epoch 91, Avg. Loss: 0.1976  Train accuracy:  0.9331  Valid. accuracy: 0.9113 elapsed=1.87\n",
      "**Epoch 92, Avg. Loss: 0.1779  Train accuracy:  0.9400  Valid. accuracy: 0.9138 elapsed=1.90\n",
      "**Epoch 93, Avg. Loss: 0.1684  Train accuracy:  0.9439  Valid. accuracy: 0.9188 elapsed=1.89\n",
      "**Epoch 94, Avg. Loss: 0.1648  Train accuracy:  0.9448  Valid. accuracy: 0.9238 elapsed=1.88\n",
      "**Epoch 95, Avg. Loss: 0.1525  Train accuracy:  0.9488  Valid. accuracy: 0.9283 elapsed=1.90\n",
      "**Epoch 96, Avg. Loss: 0.1376  Train accuracy:  0.9543  Valid. accuracy: 0.9288 elapsed=1.92\n",
      "**Epoch 97, Avg. Loss: 0.1302  Train accuracy:  0.9569  Valid. accuracy: 0.9293 elapsed=1.91\n",
      "**Epoch 98, Avg. Loss: 0.1238  Train accuracy:  0.9592  Valid. accuracy: 0.9304 elapsed=1.89\n",
      "**Epoch 99, Avg. Loss: 0.1178  Train accuracy:  0.9613  Valid. accuracy: 0.9306 elapsed=1.88\n",
      "**Epoch 100, Avg. Loss: 0.1142  Train accuracy:  0.9632  Valid. accuracy: 0.9277 elapsed=1.90\n",
      "**Epoch 101, Avg. Loss: 0.1047  Train accuracy:  0.9665  Valid. accuracy: 0.9324 elapsed=1.87\n",
      "**Epoch 102, Avg. Loss: 0.0956  Train accuracy:  0.9686  Valid. accuracy: 0.9295 elapsed=1.88\n",
      "**Epoch 103, Avg. Loss: 0.0939  Train accuracy:  0.9693  Valid. accuracy: 0.9299 elapsed=1.87\n",
      "**Epoch 104, Avg. Loss: 0.0851  Train accuracy:  0.9726  Valid. accuracy: 0.9342 elapsed=1.89\n",
      "**Epoch 105, Avg. Loss: 0.0822  Train accuracy:  0.9748  Valid. accuracy: 0.9274 elapsed=1.87\n",
      "**Epoch 106, Avg. Loss: 0.1158  Train accuracy:  0.9633  Valid. accuracy: 0.9256 elapsed=1.88\n",
      "**Epoch 107, Avg. Loss: 0.0923  Train accuracy:  0.9693  Valid. accuracy: 0.9272 elapsed=1.88\n",
      "**Epoch 108, Avg. Loss: 0.0817  Train accuracy:  0.9744  Valid. accuracy: 0.9306 elapsed=1.87\n",
      "**Epoch 109, Avg. Loss: 0.0879  Train accuracy:  0.9721  Valid. accuracy: 0.9175 elapsed=1.90\n",
      "**Epoch 110, Avg. Loss: 0.0933  Train accuracy:  0.9699  Valid. accuracy: 0.9252 elapsed=1.90\n",
      "**Epoch 111, Avg. Loss: 0.0781  Train accuracy:  0.9758  Valid. accuracy: 0.9259 elapsed=1.87\n",
      "**Epoch 112, Avg. Loss: 0.0614  Train accuracy:  0.9812  Valid. accuracy: 0.9281 elapsed=1.89\n",
      "**Epoch 113, Avg. Loss: 0.0574  Train accuracy:  0.9821  Valid. accuracy: 0.9277 elapsed=1.88\n",
      "**Epoch 114, Avg. Loss: 0.0538  Train accuracy:  0.9827  Valid. accuracy: 0.9293 elapsed=1.88\n",
      "**Epoch 115, Avg. Loss: 0.0483  Train accuracy:  0.9849  Valid. accuracy: 0.9313 elapsed=1.88\n",
      "**Epoch 116, Avg. Loss: 0.0540  Train accuracy:  0.9830  Valid. accuracy: 0.9331 elapsed=1.87\n",
      "**Epoch 117, Avg. Loss: 0.0441  Train accuracy:  0.9858  Valid. accuracy: 0.9311 elapsed=1.89\n",
      "**Epoch 118, Avg. Loss: 0.0384  Train accuracy:  0.9879  Valid. accuracy: 0.9327 elapsed=1.87\n",
      "**Epoch 119, Avg. Loss: 0.0421  Train accuracy:  0.9865  Valid. accuracy: 0.9351 elapsed=1.90\n",
      "**Epoch 120, Avg. Loss: 0.0359  Train accuracy:  0.9892  Valid. accuracy: 0.9336 elapsed=1.87\n",
      "**Epoch 121, Avg. Loss: 0.0347  Train accuracy:  0.9893  Valid. accuracy: 0.9338 elapsed=1.88\n",
      "**Epoch 122, Avg. Loss: 0.0313  Train accuracy:  0.9903  Valid. accuracy: 0.9342 elapsed=1.87\n",
      "**Epoch 123, Avg. Loss: 0.0291  Train accuracy:  0.9907  Valid. accuracy: 0.9397 elapsed=1.89\n",
      "**Epoch 124, Avg. Loss: 0.0279  Train accuracy:  0.9910  Valid. accuracy: 0.9381 elapsed=1.89\n",
      "**Epoch 125, Avg. Loss: 0.0250  Train accuracy:  0.9924  Valid. accuracy: 0.9399 elapsed=1.90\n",
      "**Epoch 126, Avg. Loss: 0.0260  Train accuracy:  0.9919  Valid. accuracy: 0.9381 elapsed=1.91\n",
      "**Epoch 127, Avg. Loss: 0.0209  Train accuracy:  0.9937  Valid. accuracy: 0.9404 elapsed=1.91\n",
      "**Epoch 128, Avg. Loss: 0.0226  Train accuracy:  0.9930  Valid. accuracy: 0.9415 elapsed=1.88\n",
      "**Epoch 129, Avg. Loss: 0.0210  Train accuracy:  0.9933  Valid. accuracy: 0.9372 elapsed=1.89\n",
      "**Epoch 130, Avg. Loss: 0.0226  Train accuracy:  0.9926  Valid. accuracy: 0.9417 elapsed=1.92\n",
      "**Epoch 131, Avg. Loss: 0.0186  Train accuracy:  0.9946  Valid. accuracy: 0.9429 elapsed=1.89\n",
      "**Epoch 132, Avg. Loss: 0.0227  Train accuracy:  0.9933  Valid. accuracy: 0.9413 elapsed=1.89\n",
      "**Epoch 133, Avg. Loss: 0.0243  Train accuracy:  0.9923  Valid. accuracy: 0.9376 elapsed=1.90\n",
      "**Epoch 134, Avg. Loss: 0.0343  Train accuracy:  0.9896  Valid. accuracy: 0.9383 elapsed=1.93\n",
      "**Epoch 135, Avg. Loss: 0.3684  Train accuracy:  0.9202  Valid. accuracy: 0.6939 elapsed=1.87\n",
      "**Epoch 136, Avg. Loss: 1.2929  Train accuracy:  0.6877  Valid. accuracy: 0.7717 elapsed=1.87\n",
      "**Epoch 137, Avg. Loss: 0.5543  Train accuracy:  0.8423  Valid. accuracy: 0.8995 elapsed=1.87\n",
      "**Epoch 138, Avg. Loss: 0.1623  Train accuracy:  0.9521  Valid. accuracy: 0.9249 elapsed=1.89\n",
      "**Epoch 139, Avg. Loss: 0.0861  Train accuracy:  0.9752  Valid. accuracy: 0.9286 elapsed=1.87\n",
      "**Epoch 140, Avg. Loss: 0.0638  Train accuracy:  0.9811  Valid. accuracy: 0.9329 elapsed=1.89\n",
      "**Epoch 141, Avg. Loss: 0.0484  Train accuracy:  0.9858  Valid. accuracy: 0.9370 elapsed=1.87\n",
      "**Epoch 142, Avg. Loss: 0.0431  Train accuracy:  0.9873  Valid. accuracy: 0.9401 elapsed=1.89\n",
      "**Epoch 143, Avg. Loss: 0.0357  Train accuracy:  0.9893  Valid. accuracy: 0.9417 elapsed=1.91\n",
      "**Epoch 144, Avg. Loss: 0.0308  Train accuracy:  0.9911  Valid. accuracy: 0.9408 elapsed=1.90\n",
      "**Epoch 145, Avg. Loss: 0.0292  Train accuracy:  0.9911  Valid. accuracy: 0.9429 elapsed=1.91\n",
      "**Epoch 146, Avg. Loss: 0.0242  Train accuracy:  0.9929  Valid. accuracy: 0.9415 elapsed=1.90\n",
      "**Epoch 147, Avg. Loss: 0.0236  Train accuracy:  0.9935  Valid. accuracy: 0.9420 elapsed=1.89\n",
      "**Epoch 148, Avg. Loss: 0.0226  Train accuracy:  0.9927  Valid. accuracy: 0.9438 elapsed=1.88\n",
      "**Epoch 149, Avg. Loss: 0.0199  Train accuracy:  0.9941  Valid. accuracy: 0.9433 elapsed=1.89\n",
      "**Epoch 150, Avg. Loss: 0.0191  Train accuracy:  0.9944  Valid. accuracy: 0.9438 elapsed=1.89\n",
      "**Epoch 151, Avg. Loss: 0.0178  Train accuracy:  0.9950  Valid. accuracy: 0.9447 elapsed=1.87\n",
      "**Epoch 152, Avg. Loss: 0.0169  Train accuracy:  0.9950  Valid. accuracy: 0.9472 elapsed=1.88\n",
      "**Epoch 153, Avg. Loss: 0.0143  Train accuracy:  0.9957  Valid. accuracy: 0.9481 elapsed=1.89\n",
      "**Epoch 154, Avg. Loss: 0.0138  Train accuracy:  0.9962  Valid. accuracy: 0.9447 elapsed=1.88\n",
      "**Epoch 155, Avg. Loss: 0.0130  Train accuracy:  0.9963  Valid. accuracy: 0.9483 elapsed=1.89\n",
      "**Epoch 156, Avg. Loss: 0.0111  Train accuracy:  0.9968  Valid. accuracy: 0.9467 elapsed=1.89\n",
      "**Epoch 157, Avg. Loss: 0.0127  Train accuracy:  0.9969  Valid. accuracy: 0.9467 elapsed=1.88\n",
      "**Epoch 158, Avg. Loss: 0.0103  Train accuracy:  0.9971  Valid. accuracy: 0.9474 elapsed=1.89\n",
      "**Epoch 159, Avg. Loss: 0.0106  Train accuracy:  0.9970  Valid. accuracy: 0.9494 elapsed=1.90\n",
      "**Epoch 160, Avg. Loss: 0.0106  Train accuracy:  0.9971  Valid. accuracy: 0.9490 elapsed=1.91\n",
      "**Epoch 161, Avg. Loss: 0.0114  Train accuracy:  0.9965  Valid. accuracy: 0.9467 elapsed=1.88\n",
      "**Epoch 162, Avg. Loss: 0.0105  Train accuracy:  0.9970  Valid. accuracy: 0.9460 elapsed=1.87\n",
      "**Epoch 163, Avg. Loss: 0.0088  Train accuracy:  0.9976  Valid. accuracy: 0.9488 elapsed=1.88\n",
      "**Epoch 164, Avg. Loss: 0.0094  Train accuracy:  0.9972  Valid. accuracy: 0.9483 elapsed=1.89\n",
      "**Epoch 165, Avg. Loss: 0.0087  Train accuracy:  0.9973  Valid. accuracy: 0.9492 elapsed=1.88\n",
      "**Epoch 166, Avg. Loss: 0.0094  Train accuracy:  0.9974  Valid. accuracy: 0.9469 elapsed=1.87\n",
      "**Epoch 167, Avg. Loss: 0.0092  Train accuracy:  0.9973  Valid. accuracy: 0.9501 elapsed=1.90\n",
      "**Epoch 168, Avg. Loss: 0.0086  Train accuracy:  0.9975  Valid. accuracy: 0.9463 elapsed=1.89\n",
      "**Epoch 169, Avg. Loss: 0.0079  Train accuracy:  0.9977  Valid. accuracy: 0.9474 elapsed=1.90\n",
      "**Epoch 170, Avg. Loss: 0.0078  Train accuracy:  0.9978  Valid. accuracy: 0.9481 elapsed=1.89\n",
      "**Epoch 171, Avg. Loss: 0.0063  Train accuracy:  0.9982  Valid. accuracy: 0.9476 elapsed=1.88\n",
      "**Epoch 172, Avg. Loss: 0.0087  Train accuracy:  0.9973  Valid. accuracy: 0.9503 elapsed=1.87\n",
      "**Epoch 173, Avg. Loss: 0.0075  Train accuracy:  0.9976  Valid. accuracy: 0.9499 elapsed=1.90\n",
      "**Epoch 174, Avg. Loss: 0.0080  Train accuracy:  0.9976  Valid. accuracy: 0.9483 elapsed=1.88\n",
      "**Epoch 175, Avg. Loss: 0.0090  Train accuracy:  0.9975  Valid. accuracy: 0.9508 elapsed=1.88\n",
      "**Epoch 176, Avg. Loss: 0.0077  Train accuracy:  0.9977  Valid. accuracy: 0.9469 elapsed=1.88\n",
      "**Epoch 177, Avg. Loss: 0.0082  Train accuracy:  0.9974  Valid. accuracy: 0.9506 elapsed=1.89\n",
      "**Epoch 178, Avg. Loss: 0.0077  Train accuracy:  0.9979  Valid. accuracy: 0.9499 elapsed=1.89\n",
      "**Epoch 179, Avg. Loss: 0.0074  Train accuracy:  0.9979  Valid. accuracy: 0.9456 elapsed=1.89\n",
      "**Epoch 180, Avg. Loss: 0.0139  Train accuracy:  0.9965  Valid. accuracy: 0.9381 elapsed=1.88\n",
      "**Epoch 181, Avg. Loss: 0.0716  Train accuracy:  0.9810  Valid. accuracy: 0.8995 elapsed=1.87\n",
      "**Epoch 182, Avg. Loss: 0.5394  Train accuracy:  0.8780  Valid. accuracy: 0.7964 elapsed=1.87\n",
      "**Epoch 183, Avg. Loss: 0.4896  Train accuracy:  0.8686  Valid. accuracy: 0.8617 elapsed=1.87\n",
      "**Epoch 184, Avg. Loss: 0.2506  Train accuracy:  0.9261  Valid. accuracy: 0.9315 elapsed=1.88\n",
      "**Epoch 185, Avg. Loss: 0.0671  Train accuracy:  0.9801  Valid. accuracy: 0.9361 elapsed=1.89\n",
      "**Epoch 186, Avg. Loss: 0.0375  Train accuracy:  0.9894  Valid. accuracy: 0.9392 elapsed=1.87\n",
      "**Epoch 187, Avg. Loss: 0.0248  Train accuracy:  0.9935  Valid. accuracy: 0.9451 elapsed=1.86\n",
      "**Epoch 188, Avg. Loss: 0.0180  Train accuracy:  0.9950  Valid. accuracy: 0.9454 elapsed=1.87\n",
      "**Epoch 189, Avg. Loss: 0.0143  Train accuracy:  0.9964  Valid. accuracy: 0.9438 elapsed=1.88\n",
      "**Epoch 190, Avg. Loss: 0.0127  Train accuracy:  0.9966  Valid. accuracy: 0.9463 elapsed=1.87\n",
      "**Epoch 191, Avg. Loss: 0.0112  Train accuracy:  0.9973  Valid. accuracy: 0.9467 elapsed=1.87\n",
      "**Epoch 192, Avg. Loss: 0.0092  Train accuracy:  0.9978  Valid. accuracy: 0.9488 elapsed=1.87\n",
      "**Epoch 193, Avg. Loss: 0.0090  Train accuracy:  0.9979  Valid. accuracy: 0.9488 elapsed=1.89\n",
      "**Epoch 194, Avg. Loss: 0.0082  Train accuracy:  0.9979  Valid. accuracy: 0.9485 elapsed=1.89\n",
      "**Epoch 195, Avg. Loss: 0.0077  Train accuracy:  0.9982  Valid. accuracy: 0.9476 elapsed=1.88\n",
      "**Epoch 196, Avg. Loss: 0.0076  Train accuracy:  0.9981  Valid. accuracy: 0.9485 elapsed=1.90\n",
      "**Epoch 197, Avg. Loss: 0.0077  Train accuracy:  0.9978  Valid. accuracy: 0.9481 elapsed=1.91\n",
      "**Epoch 198, Avg. Loss: 0.0062  Train accuracy:  0.9985  Valid. accuracy: 0.9497 elapsed=1.91\n",
      "**Epoch 199, Avg. Loss: 0.0054  Train accuracy:  0.9987  Valid. accuracy: 0.9490 elapsed=1.88\n",
      "**Epoch 200, Avg. Loss: 0.0068  Train accuracy:  0.9982  Valid. accuracy: 0.9483 elapsed=1.89\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      "Writing to experiment_results/exp_c6d23e3b.pkl\n",
      "\n",
      " Experiment 12/36 :\n",
      "\n",
      "{'batch_size': 512,\n",
      " 'keep_prob': 0.7,\n",
      " 'learning_rate': 0.001,\n",
      " 'netw_arch_name': 'arch_3_3'}\n",
      " 1 conv1        conv2d           [30, 30, 16]     #params:     448\n",
      " 2 max_p1       max_pool         [15, 15, 16]     #params:       0\n",
      " 3 conv2        conv2d           [13, 13, 32]     #params:    4640\n",
      " 4 max_p2       max_pool         [7, 7, 32]       #params:       0\n",
      " 5 conv3        conv2d           [3, 3, 16]       #params:   12816\n",
      " 6 max_p3       max_pool         [2, 2, 16]       #params:       0\n",
      " 7 flat1        flatten          [64]             #params:       0\n",
      " 8 fc1          fully_connected  [120]            #params:    7800\n",
      " 9 dropout_1    dropout          [120]            #params:       0\n",
      "10 fc2          fully_connected  [84]             #params:   10164\n",
      "11 dropout_2    dropout          [84]             #params:       0\n",
      "no non-linearity\n",
      "12 logits       fully_connected  [43]             #params:    3655\n",
      "Total params:   39523\n",
      "Initializing batches_generator: batch_size= 512 n_batches= 67\n",
      "**Epoch  1, Avg. Loss: 3.9862  Train accuracy:  0.0092  Valid. accuracy: 0.0556 elapsed=1.93\n",
      "**Epoch  2, Avg. Loss: 3.7588  Train accuracy:  0.0582  Valid. accuracy: 0.0549 elapsed=1.91\n",
      "**Epoch  3, Avg. Loss: 3.7468  Train accuracy:  0.0501  Valid. accuracy: 0.0580 elapsed=1.88\n",
      "**Epoch  4, Avg. Loss: 3.7364  Train accuracy:  0.0268  Valid. accuracy: 0.0277 elapsed=1.88\n",
      "**Epoch  5, Avg. Loss: 3.7156  Train accuracy:  0.0238  Valid. accuracy: 0.0329 elapsed=1.87\n",
      "**Epoch  6, Avg. Loss: 3.6867  Train accuracy:  0.0296  Valid. accuracy: 0.0374 elapsed=1.90\n",
      "**Epoch  7, Avg. Loss: 3.6146  Train accuracy:  0.0675  Valid. accuracy: 0.0546 elapsed=1.87\n",
      "**Epoch  8, Avg. Loss: 3.6221  Train accuracy:  0.0380  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch  9, Avg. Loss: 3.6016  Train accuracy:  0.0443  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 10, Avg. Loss: 3.5822  Train accuracy:  0.0449  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 11, Avg. Loss: 3.5698  Train accuracy:  0.0462  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 12, Avg. Loss: 3.5635  Train accuracy:  0.0447  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 13, Avg. Loss: 3.5566  Train accuracy:  0.0456  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 14, Avg. Loss: 3.5499  Train accuracy:  0.0447  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 15, Avg. Loss: 3.5493  Train accuracy:  0.0460  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 16, Avg. Loss: 3.5442  Train accuracy:  0.0451  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 17, Avg. Loss: 3.5462  Train accuracy:  0.0449  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 18, Avg. Loss: 3.5410  Train accuracy:  0.0433  Valid. accuracy: 0.0546 elapsed=1.87\n",
      "**Epoch 19, Avg. Loss: 3.5388  Train accuracy:  0.0430  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 20, Avg. Loss: 3.5379  Train accuracy:  0.0415  Valid. accuracy: 0.0553 elapsed=1.88\n",
      "**Epoch 21, Avg. Loss: 3.5360  Train accuracy:  0.0419  Valid. accuracy: 0.0651 elapsed=1.88\n",
      "**Epoch 22, Avg. Loss: 3.5364  Train accuracy:  0.0429  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 23, Avg. Loss: 3.5344  Train accuracy:  0.0427  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 24, Avg. Loss: 3.5317  Train accuracy:  0.0433  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 25, Avg. Loss: 3.5307  Train accuracy:  0.0420  Valid. accuracy: 0.0546 elapsed=1.89\n",
      "**Epoch 26, Avg. Loss: 3.5282  Train accuracy:  0.0409  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 27, Avg. Loss: 3.5282  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 28, Avg. Loss: 3.5597  Train accuracy:  0.0964  Valid. accuracy: 0.0805 elapsed=1.89\n",
      "**Epoch 29, Avg. Loss: 3.5460  Train accuracy:  0.0909  Valid. accuracy: 0.0608 elapsed=1.88\n",
      "**Epoch 30, Avg. Loss: 3.5292  Train accuracy:  0.0475  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 31, Avg. Loss: 3.5288  Train accuracy:  0.0475  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 32, Avg. Loss: 3.5266  Train accuracy:  0.0452  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 33, Avg. Loss: 3.5269  Train accuracy:  0.0452  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 34, Avg. Loss: 3.5246  Train accuracy:  0.0471  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 35, Avg. Loss: 3.5256  Train accuracy:  0.0445  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 36, Avg. Loss: 3.5231  Train accuracy:  0.0435  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 37, Avg. Loss: 3.5254  Train accuracy:  0.0449  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 38, Avg. Loss: 3.5229  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 39, Avg. Loss: 3.5226  Train accuracy:  0.0417  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 40, Avg. Loss: 3.5236  Train accuracy:  0.0413  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 41, Avg. Loss: 3.5208  Train accuracy:  0.0417  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 42, Avg. Loss: 3.5208  Train accuracy:  0.0427  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 43, Avg. Loss: 3.5220  Train accuracy:  0.0408  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 44, Avg. Loss: 3.5206  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 45, Avg. Loss: 3.5183  Train accuracy:  0.0447  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 46, Avg. Loss: 3.5426  Train accuracy:  0.0427  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 47, Avg. Loss: 3.5191  Train accuracy:  0.0408  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 48, Avg. Loss: 3.5198  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 49, Avg. Loss: 3.5184  Train accuracy:  0.0410  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 50, Avg. Loss: 3.5195  Train accuracy:  0.0401  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 51, Avg. Loss: 3.5190  Train accuracy:  0.0402  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 52, Avg. Loss: 3.5172  Train accuracy:  0.0401  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 53, Avg. Loss: 3.5159  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 54, Avg. Loss: 3.5185  Train accuracy:  0.0422  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 55, Avg. Loss: 3.5167  Train accuracy:  0.0405  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 56, Avg. Loss: 3.5176  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 57, Avg. Loss: 3.5154  Train accuracy:  0.0419  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 58, Avg. Loss: 3.5168  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 59, Avg. Loss: 3.5158  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 60, Avg. Loss: 3.5160  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 61, Avg. Loss: 3.5154  Train accuracy:  0.0397  Valid. accuracy: 0.0544 elapsed=1.91\n",
      "**Epoch 62, Avg. Loss: 3.5176  Train accuracy:  0.0413  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 63, Avg. Loss: 3.5147  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 64, Avg. Loss: 3.5148  Train accuracy:  0.0408  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 65, Avg. Loss: 3.5131  Train accuracy:  0.0427  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 66, Avg. Loss: 3.5140  Train accuracy:  0.0398  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 67, Avg. Loss: 3.5130  Train accuracy:  0.0398  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 68, Avg. Loss: 3.5135  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 69, Avg. Loss: 3.5121  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 70, Avg. Loss: 3.5129  Train accuracy:  0.0407  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 71, Avg. Loss: 3.5116  Train accuracy:  0.0400  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 72, Avg. Loss: 3.5122  Train accuracy:  0.0407  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 73, Avg. Loss: 3.5131  Train accuracy:  0.0391  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 74, Avg. Loss: 3.5139  Train accuracy:  0.0394  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 75, Avg. Loss: 3.5144  Train accuracy:  0.0387  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 76, Avg. Loss: 3.5133  Train accuracy:  0.0396  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 77, Avg. Loss: 3.5116  Train accuracy:  0.0396  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 78, Avg. Loss: 3.5119  Train accuracy:  0.0408  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 79, Avg. Loss: 3.5108  Train accuracy:  0.0391  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 80, Avg. Loss: 3.5103  Train accuracy:  0.0404  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 81, Avg. Loss: 3.5110  Train accuracy:  0.0379  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 82, Avg. Loss: 3.5096  Train accuracy:  0.0410  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 83, Avg. Loss: 3.5106  Train accuracy:  0.0396  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 84, Avg. Loss: 3.5117  Train accuracy:  0.0401  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 85, Avg. Loss: 3.5106  Train accuracy:  0.0390  Valid. accuracy: 0.0544 elapsed=1.90\n",
      "**Epoch 86, Avg. Loss: 3.5087  Train accuracy:  0.0398  Valid. accuracy: 0.0544 elapsed=1.94\n",
      "**Epoch 87, Avg. Loss: 3.5098  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.91\n",
      "**Epoch 88, Avg. Loss: 3.5089  Train accuracy:  0.0406  Valid. accuracy: 0.0544 elapsed=1.93\n",
      "**Epoch 89, Avg. Loss: 3.5092  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.93\n",
      "**Epoch 90, Avg. Loss: 3.5105  Train accuracy:  0.0391  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 91, Avg. Loss: 3.5099  Train accuracy:  0.0397  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 92, Avg. Loss: 3.5081  Train accuracy:  0.0400  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 93, Avg. Loss: 3.5083  Train accuracy:  0.0405  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 94, Avg. Loss: 3.5096  Train accuracy:  0.0400  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 95, Avg. Loss: 3.5101  Train accuracy:  0.0403  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 96, Avg. Loss: 3.5091  Train accuracy:  0.0388  Valid. accuracy: 0.0544 elapsed=1.92\n",
      "**Epoch 97, Avg. Loss: 3.5085  Train accuracy:  0.0397  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 98, Avg. Loss: 3.5085  Train accuracy:  0.0383  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 99, Avg. Loss: 3.5082  Train accuracy:  0.0382  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 100, Avg. Loss: 3.5092  Train accuracy:  0.0401  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 101, Avg. Loss: 3.5078  Train accuracy:  0.0375  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 102, Avg. Loss: 3.5084  Train accuracy:  0.0395  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 103, Avg. Loss: 3.5082  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 104, Avg. Loss: 3.5073  Train accuracy:  0.0382  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 105, Avg. Loss: 3.5071  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 106, Avg. Loss: 3.5078  Train accuracy:  0.0377  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 107, Avg. Loss: 3.5081  Train accuracy:  0.0372  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 108, Avg. Loss: 3.5067  Train accuracy:  0.0375  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 109, Avg. Loss: 3.5072  Train accuracy:  0.0380  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 110, Avg. Loss: 3.5063  Train accuracy:  0.0400  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 111, Avg. Loss: 3.5072  Train accuracy:  0.0368  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 112, Avg. Loss: 3.5068  Train accuracy:  0.0377  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 113, Avg. Loss: 3.5056  Train accuracy:  0.0375  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 114, Avg. Loss: 3.5058  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.89\n",
      "**Epoch 115, Avg. Loss: 3.5069  Train accuracy:  0.0385  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 116, Avg. Loss: 3.5069  Train accuracy:  0.0374  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 117, Avg. Loss: 3.5054  Train accuracy:  0.0369  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 118, Avg. Loss: 3.5050  Train accuracy:  0.0390  Valid. accuracy: 0.0544 elapsed=1.88\n",
      "**Epoch 119, Avg. Loss: 3.5059  Train accuracy:  0.0377  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 120, Avg. Loss: 3.5050  Train accuracy:  0.0371  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 121, Avg. Loss: 3.5059  Train accuracy:  0.0377  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 122, Avg. Loss: 3.5048  Train accuracy:  0.0383  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 123, Avg. Loss: 3.5056  Train accuracy:  0.0363  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 124, Avg. Loss: 3.5055  Train accuracy:  0.0394  Valid. accuracy: 0.0544 elapsed=1.87\n",
      "**Epoch 125, Avg. Loss: 3.5053  Train accuracy:  0.0382  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 126, Avg. Loss: 3.5037  Train accuracy:  0.0382  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 127, Avg. Loss: 3.5044  Train accuracy:  0.0362  Valid. accuracy: 0.0544 elapsed=1.86\n",
      "**Epoch 128, Avg. Loss: 3.5048  Train accuracy:  0.0369  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 129, Avg. Loss: 3.5047  Train accuracy:  0.0371  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 130, Avg. Loss: 3.5040  Train accuracy:  0.0372  Valid. accuracy: 0.0544 elapsed=1.83\n",
      "**Epoch 131, Avg. Loss: 3.5040  Train accuracy:  0.0355  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 132, Avg. Loss: 3.5029  Train accuracy:  0.0385  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 133, Avg. Loss: 3.5030  Train accuracy:  0.0368  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 134, Avg. Loss: 3.5035  Train accuracy:  0.0376  Valid. accuracy: 0.0812 elapsed=1.84\n",
      "**Epoch 135, Avg. Loss: 3.5129  Train accuracy:  0.0429  Valid. accuracy: 0.0542 elapsed=1.84\n",
      "**Epoch 136, Avg. Loss: 3.5039  Train accuracy:  0.0336  Valid. accuracy: 0.1036 elapsed=1.84\n",
      "**Epoch 137, Avg. Loss: 3.4731  Train accuracy:  0.0601  Valid. accuracy: 0.0603 elapsed=1.84\n",
      "**Epoch 138, Avg. Loss: 3.3639  Train accuracy:  0.0461  Valid. accuracy: 0.0721 elapsed=1.85\n",
      "**Epoch 139, Avg. Loss: 3.2663  Train accuracy:  0.0722  Valid. accuracy: 0.1045 elapsed=1.84\n",
      "**Epoch 140, Avg. Loss: 3.2621  Train accuracy:  0.0819  Valid. accuracy: 0.1279 elapsed=1.85\n",
      "**Epoch 141, Avg. Loss: 3.3831  Train accuracy:  0.0712  Valid. accuracy: 0.0546 elapsed=1.84\n",
      "**Epoch 142, Avg. Loss: 3.5128  Train accuracy:  0.0375  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 143, Avg. Loss: 3.5076  Train accuracy:  0.0389  Valid. accuracy: 0.0544 elapsed=1.85\n",
      "**Epoch 144, Avg. Loss: 3.5067  Train accuracy:  0.0384  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 145, Avg. Loss: 3.5051  Train accuracy:  0.0382  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 146, Avg. Loss: 3.5051  Train accuracy:  0.0387  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 147, Avg. Loss: 3.5040  Train accuracy:  0.0412  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 148, Avg. Loss: 3.5041  Train accuracy:  0.0398  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 149, Avg. Loss: 3.5037  Train accuracy:  0.0399  Valid. accuracy: 0.0544 elapsed=1.84\n",
      "**Epoch 150, Avg. Loss: 3.4329  Train accuracy:  0.0222  Valid. accuracy: 0.0964 elapsed=1.85\n",
      "**Epoch 151, Avg. Loss: 3.1903  Train accuracy:  0.0885  Valid. accuracy: 0.1311 elapsed=1.86\n",
      "**Epoch 152, Avg. Loss: 3.2655  Train accuracy:  0.0694  Valid. accuracy: 0.1390 elapsed=1.86\n",
      "**Epoch 153, Avg. Loss: 3.1097  Train accuracy:  0.0907  Valid. accuracy: 0.1732 elapsed=1.84\n",
      "**Epoch 154, Avg. Loss: 2.9989  Train accuracy:  0.1026  Valid. accuracy: 0.1780 elapsed=1.84\n",
      "**Epoch 155, Avg. Loss: 2.9135  Train accuracy:  0.1412  Valid. accuracy: 0.1782 elapsed=1.84\n",
      "**Epoch 156, Avg. Loss: 2.8424  Train accuracy:  0.1547  Valid. accuracy: 0.1782 elapsed=1.84\n",
      "**Epoch 157, Avg. Loss: 2.7818  Train accuracy:  0.1628  Valid. accuracy: 0.1875 elapsed=1.84\n",
      "**Epoch 158, Avg. Loss: 2.7212  Train accuracy:  0.1737  Valid. accuracy: 0.2367 elapsed=1.83\n",
      "**Epoch 159, Avg. Loss: 2.6379  Train accuracy:  0.1959  Valid. accuracy: 0.2651 elapsed=1.84\n",
      "**Epoch 160, Avg. Loss: 2.5577  Train accuracy:  0.2027  Valid. accuracy: 0.2739 elapsed=1.85\n",
      "**Epoch 161, Avg. Loss: 2.4839  Train accuracy:  0.2243  Valid. accuracy: 0.2737 elapsed=1.85\n",
      "**Epoch 162, Avg. Loss: 2.3993  Train accuracy:  0.2310  Valid. accuracy: 0.2880 elapsed=1.84\n",
      "**Epoch 163, Avg. Loss: 2.3422  Train accuracy:  0.2325  Valid. accuracy: 0.2966 elapsed=1.85\n",
      "**Epoch 164, Avg. Loss: 2.2898  Train accuracy:  0.2359  Valid. accuracy: 0.3057 elapsed=1.85\n",
      "**Epoch 165, Avg. Loss: 2.2250  Train accuracy:  0.2536  Valid. accuracy: 0.3252 elapsed=1.85\n",
      "**Epoch 166, Avg. Loss: 2.1852  Train accuracy:  0.2626  Valid. accuracy: 0.3578 elapsed=1.86\n",
      "**Epoch 167, Avg. Loss: 2.1246  Train accuracy:  0.2781  Valid. accuracy: 0.3465 elapsed=1.85\n",
      "**Epoch 168, Avg. Loss: 2.0660  Train accuracy:  0.2954  Valid. accuracy: 0.3601 elapsed=1.85\n",
      "**Epoch 169, Avg. Loss: 2.0018  Train accuracy:  0.3128  Valid. accuracy: 0.3565 elapsed=1.86\n",
      "**Epoch 170, Avg. Loss: 1.9699  Train accuracy:  0.3180  Valid. accuracy: 0.3995 elapsed=1.85\n",
      "**Epoch 171, Avg. Loss: 1.9283  Train accuracy:  0.3284  Valid. accuracy: 0.3918 elapsed=1.85\n",
      "**Epoch 172, Avg. Loss: 1.8838  Train accuracy:  0.3524  Valid. accuracy: 0.4315 elapsed=1.88\n",
      "**Epoch 173, Avg. Loss: 1.7542  Train accuracy:  0.3814  Valid. accuracy: 0.4553 elapsed=1.89\n",
      "**Epoch 174, Avg. Loss: 1.6923  Train accuracy:  0.4026  Valid. accuracy: 0.4880 elapsed=1.88\n",
      "**Epoch 175, Avg. Loss: 1.5969  Train accuracy:  0.4371  Valid. accuracy: 0.5048 elapsed=1.87\n",
      "**Epoch 176, Avg. Loss: 1.5509  Train accuracy:  0.4478  Valid. accuracy: 0.5256 elapsed=1.85\n",
      "**Epoch 177, Avg. Loss: 1.4878  Train accuracy:  0.4652  Valid. accuracy: 0.5297 elapsed=1.86\n",
      "**Epoch 178, Avg. Loss: 1.4626  Train accuracy:  0.4758  Valid. accuracy: 0.5594 elapsed=1.85\n",
      "**Epoch 179, Avg. Loss: 1.4332  Train accuracy:  0.4893  Valid. accuracy: 0.5526 elapsed=1.86\n",
      "**Epoch 180, Avg. Loss: 1.3937  Train accuracy:  0.5018  Valid. accuracy: 0.5755 elapsed=1.86\n",
      "**Epoch 181, Avg. Loss: 1.3375  Train accuracy:  0.5138  Valid. accuracy: 0.5875 elapsed=1.87\n",
      "**Epoch 182, Avg. Loss: 1.2576  Train accuracy:  0.5294  Valid. accuracy: 0.6048 elapsed=1.88\n",
      "**Epoch 183, Avg. Loss: 1.1875  Train accuracy:  0.5415  Valid. accuracy: 0.6147 elapsed=1.88\n",
      "**Epoch 184, Avg. Loss: 1.1711  Train accuracy:  0.5482  Valid. accuracy: 0.6431 elapsed=1.87\n",
      "**Epoch 185, Avg. Loss: 1.0987  Train accuracy:  0.5666  Valid. accuracy: 0.6601 elapsed=1.88\n",
      "**Epoch 186, Avg. Loss: 1.0376  Train accuracy:  0.5816  Valid. accuracy: 0.6961 elapsed=1.88\n",
      "**Epoch 187, Avg. Loss: 0.9616  Train accuracy:  0.6184  Valid. accuracy: 0.7059 elapsed=1.88\n",
      "**Epoch 188, Avg. Loss: 0.9201  Train accuracy:  0.6325  Valid. accuracy: 0.7177 elapsed=1.87\n",
      "**Epoch 189, Avg. Loss: 0.8785  Train accuracy:  0.6462  Valid. accuracy: 0.7286 elapsed=1.88\n",
      "**Epoch 190, Avg. Loss: 0.8329  Train accuracy:  0.6644  Valid. accuracy: 0.7336 elapsed=1.88\n",
      "**Epoch 191, Avg. Loss: 0.7932  Train accuracy:  0.6793  Valid. accuracy: 0.7469 elapsed=1.88\n",
      "**Epoch 192, Avg. Loss: 0.7756  Train accuracy:  0.6867  Valid. accuracy: 0.7501 elapsed=1.86\n",
      "**Epoch 193, Avg. Loss: 0.7612  Train accuracy:  0.6932  Valid. accuracy: 0.7642 elapsed=1.88\n",
      "**Epoch 194, Avg. Loss: 0.7092  Train accuracy:  0.7193  Valid. accuracy: 0.7694 elapsed=1.88\n",
      "**Epoch 195, Avg. Loss: 0.6736  Train accuracy:  0.7365  Valid. accuracy: 0.7698 elapsed=1.88\n"
     ]
    }
   ],
   "source": [
    "reload( h )\n",
    "lattice_specs = [\n",
    "    ( \"netw_arch_name\", [\"arch_3_3\", \"arch_3_3_2fc\", \"arch_3_3_b\"] ),\n",
    "    ( \"learning_rate\" , [ 0.0005, 0.0010 ] ),                         \n",
    "    ( \"batch_size\" , [ 256, 512] ),\n",
    "    ( \"keep_prob\"  , [ 0.9, 0.8, 0.7] ),    \n",
    "]\n",
    "\n",
    "def to_pickle( obj, fname ) : \n",
    "    with open( fname, \"wb\") as f_out :\n",
    "        print( \"Writing to \" + fname )\n",
    "        pickle.dump( obj, f_out )\n",
    "\n",
    "hyp_par_dicts = h.make_hyp_par_dicts( lattice_specs )\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "for exp_i, hyp_pars in enumerate( hyp_par_dicts ) :\n",
    "    print( f\"\\n Experiment {exp_i + 1}/{len(hyp_par_dicts)} :\\n\")\n",
    "    \n",
    "    pprint( hyp_pars )    \n",
    "    result = hyp_pars.copy()\n",
    "    \n",
    "    md5_dig, out_path = md5_digest_from_pars( hyp_pars )\n",
    "    \n",
    "    if os.path.exists( out_path ) :\n",
    "        print( out_path + \" already there.\")\n",
    "        continue \n",
    "    \n",
    "    result[\"md5_dig\"] = md5_dig\n",
    "    per_epoch = h.run_training( data, hyp_pars, log_pars, n_epochs = 200) \n",
    "    #print(\"\\n\", per_epoch, \"\\n\")\n",
    "    \n",
    "    result[\"best_valid_accy\"] = per_epoch[\"valid_accy\"].max()    \n",
    "    result[\"best_valid_epoch\"] = per_epoch['valid_accy'].idxmax()\n",
    "    \n",
    "    pprint( hyp_pars )\n",
    "    result[\"per_epoch\"] = per_epoch    \n",
    "    to_pickle( result,  out_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tf.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 (Optional): Visualize the Neural Network's State with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
